{
    "archive_path": "archive/1632689273.123244",
    "base_url": "en.wikipedia.org/wiki/Integrated_information_theory",
    "basename": "Integrated_information_theory",
    "bookmarked_date": "2021-09-26 20:47",
    "canonical": {
        "archive_org_path": "https://web.archive.org/web/en.wikipedia.org/wiki/Integrated_information_theory",
        "dom_path": "output.html",
        "favicon_path": "favicon.ico",
        "git_path": "git/",
        "google_favicon_path": "https://www.google.com/s2/favicons?domain=en.wikipedia.org",
        "headers_path": "headers.json",
        "index_path": "index.html",
        "media_path": "media/",
        "mercury_path": "mercury/content.html",
        "pdf_path": "output.pdf",
        "readability_path": "readability/content.html",
        "screenshot_path": "screenshot.png",
        "singlefile_path": "singlefile.html",
        "warc_path": "warc/",
        "wget_path": null
    },
    "domain": "en.wikipedia.org",
    "extension": "",
    "hash": "1E5DJW3DP8ES8WN4ZRZA",
    "history": {
        "archive_org": [
            {
                "cmd": [
                    "curl",
                    "--silent",
                    "--location",
                    "--compressed",
                    "--head",
                    "--max-time",
                    "90",
                    "--user-agent",
                    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.61 Safari/537.36 ArchiveBox/0.6.2 (+https://github.com/ArchiveBox/ArchiveBox/) curl/curl 7.76.1 (x86_64-pc-linux-gnu)",
                    "https://web.archive.org/save/https://en.wikipedia.org/wiki/Integrated_information_theory"
                ],
                "cmd_version": "curl 7.76.1 (x86_64-pc-linux-gnu)",
                "end_ts": "2021-09-26T20:48:32.557179+00:00",
                "index_texts": null,
                "output": "https://web.archive.org/web/20210926204820/https://en.wikipedia.org/wiki/Integrated_information_theory",
                "pwd": "/home/wesleyac/code/notebook/data/archivebox/archive/1632689273.123244",
                "schema": "ArchiveResult",
                "start_ts": "2021-09-26T20:48:18.064777+00:00",
                "status": "succeeded"
            }
        ],
        "dom": [
            {
                "cmd": [
                    "chromium-browser",
                    "--headless",
                    "--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.61 Safari/537.36 ArchiveBox/{VERSION} (+https://github.com/ArchiveBox/ArchiveBox/)",
                    "--window-size=1440,2000",
                    "--timeout=90000",
                    "--dump-dom",
                    "https://en.wikipedia.org/wiki/Integrated_information_theory"
                ],
                "cmd_version": "Chromium 93.0.4577.82",
                "end_ts": "2021-09-26T20:48:05.475334+00:00",
                "index_texts": null,
                "output": "output.html",
                "pwd": "/home/wesleyac/code/notebook/data/archivebox/archive/1632689273.123244",
                "schema": "ArchiveResult",
                "start_ts": "2021-09-26T20:48:04.185955+00:00",
                "status": "succeeded"
            }
        ],
        "favicon": [
            {
                "cmd": [
                    "curl",
                    "--silent",
                    "--location",
                    "--compressed",
                    "--max-time",
                    "90",
                    "--output",
                    "favicon.ico",
                    "--user-agent",
                    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.61 Safari/537.36 ArchiveBox/0.6.2 (+https://github.com/ArchiveBox/ArchiveBox/) curl/curl 7.76.1 (x86_64-pc-linux-gnu)",
                    "https://www.google.com/s2/favicons?domain=en.wikipedia.org"
                ],
                "cmd_version": "curl 7.76.1 (x86_64-pc-linux-gnu)",
                "end_ts": "2021-09-26T20:47:53.878056+00:00",
                "index_texts": null,
                "output": "favicon.ico",
                "pwd": "/home/wesleyac/code/notebook/data/archivebox/archive/1632689273.123244",
                "schema": "ArchiveResult",
                "start_ts": "2021-09-26T20:47:53.678601+00:00",
                "status": "succeeded"
            }
        ],
        "git": [],
        "headers": [
            {
                "cmd": [
                    "curl",
                    "--silent",
                    "--location",
                    "--compressed",
                    "--head",
                    "--max-time",
                    "90",
                    "--user-agent",
                    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.61 Safari/537.36 ArchiveBox/0.6.2 (+https://github.com/ArchiveBox/ArchiveBox/) curl/curl 7.76.1 (x86_64-pc-linux-gnu)",
                    "https://en.wikipedia.org/wiki/Integrated_information_theory"
                ],
                "cmd_version": "curl 7.76.1 (x86_64-pc-linux-gnu)",
                "end_ts": "2021-09-26T20:47:54.039817+00:00",
                "index_texts": null,
                "output": "headers.json",
                "pwd": "/home/wesleyac/code/notebook/data/archivebox/archive/1632689273.123244",
                "schema": "ArchiveResult",
                "start_ts": "2021-09-26T20:47:53.891135+00:00",
                "status": "succeeded"
            }
        ],
        "media": [],
        "mercury": [
            {
                "cmd": [
                    "/home/wesleyac/code/notebook/data/archivebox/node_modules/@postlight/mercury-parser/cli.js",
                    "https://en.wikipedia.org/wiki/Integrated_information_theory"
                ],
                "cmd_version": "1.0.0",
                "end_ts": "2021-09-26T20:48:18.043353+00:00",
                "index_texts": null,
                "output": "mercury",
                "pwd": "/home/wesleyac/code/notebook/data/archivebox/archive/1632689273.123244",
                "schema": "ArchiveResult",
                "start_ts": "2021-09-26T20:48:12.953945+00:00",
                "status": "succeeded"
            }
        ],
        "pdf": [],
        "readability": [
            {
                "cmd": [
                    "/home/wesleyac/code/notebook/data/archivebox/node_modules/readability-extractor/readability-extractor",
                    "/run/user/1000/tmpjzq9rhwe"
                ],
                "cmd_version": "0.0.3",
                "end_ts": "2021-09-26T20:48:12.932107+00:00",
                "index_texts": [
                    "\nPhi, the symbol used for integrated information\nIntegrated information theory (IIT) attempts to provide a framework capable of explaining why some physical systems (such as human brains) are conscious,[1] why they feel the particular way they do in particular states (e.g. why our visual field appears extended when we gaze out at the night sky),[2] and what it would take for other physical systems to be conscious (are dogs conscious? what about unborn babies? or computers?).[3] In principle, once the theory is mature and has been tested extensively in controlled conditions, the IIT framework may be capable of providing a concrete inference about whether any physical system is conscious, to what degree it is conscious, and what particular experience it is having. In IIT, a system's consciousness (what it is like subjectively) is conjectured to be identical to its causal properties (what it is like objectively). Therefore it should be possible to account for the conscious experience of a physical system by unfolding its complete causal powers (see Central identity).[4]\nIIT was proposed by neuroscientist Giulio Tononi in 2004.[5] The latest version of the theory, labeled IIT 3.0, was published in 2014.[6][1] However, the theory is still in development, as is evident from the later publications improving on the formalism presented in IIT 3.0.[7][2][8][9]\n\n\n\nOverview[edit]\nRelationship to the \"hard problem of consciousness\"[edit]\nDavid Chalmers has argued that any attempt to explain consciousness in purely physical terms (i.e. to start with the laws of physics as they are currently formulated and derive the necessary and inevitable existence of consciousness) eventually runs into the so-called \"hard problem\". Rather than try to start from physical principles and arrive at consciousness, IIT \"starts with consciousness\" (accepts the existence of our own consciousness as certain) and reasons about the properties that a postulated physical substrate would need to have in order to account for it. The ability to perform this jump from phenomenology to mechanism rests on IIT's assumption that if the formal properties of a conscious experience can be fully accounted for by an underlying physical system, then the properties of the physical system must be constrained by the properties of the experience. The limitations on the physical system for consciousness to exist is unknown and may exist on spectrum implied by studies involving split brain patients and conscious patients with large amounts of brain matter missing.\nSpecifically, IIT moves from phenomenology to mechanism by attempting to identify the essential properties of conscious experience (dubbed \"axioms\") and, from there, the essential properties of conscious physical systems (dubbed \"postulates\").\n\nAxioms: essential properties of experience[edit]\nAxioms and postulates of integrated information theory\nThe axioms are intended to capture the essential aspects of every conscious experience. Every axiom should apply to every possible experience.\nThe wording of the axioms has changed slightly as the theory has developed, and the most recent and complete statement of the axioms is as follows: \n\n\nIntrinsic existence: Consciousness exists: each experience is actual\u2014indeed, that my experience here and now exists (it is real) is the only fact I can be sure of immediately and absolutely. Moreover, my experience exists from its own intrinsic perspective, independent of external observers (it is intrinsically real or actual).\nComposition: Consciousness is structured: each experience is composed of multiple phenomenological distinctions, elementary or higher-order. For example, within one experience I may distinguish a book, a blue color, a blue book, the left side, a blue book on the left, and so on.\nInformation: Consciousness is specific: each experience is the particular way it is\u2014being composed of a specific set of specific phenomenal distinctions\u2014thereby differing from other possible experiences (differentiation). For example, an experience may include phenomenal distinctions specifying a large number of spatial locations, several positive concepts, such as a bedroom (as opposed to no bedroom), a bed (as opposed to no bed), a book (as opposed to no book), a blue color (as opposed to no blue), higher-order \"bindings\" of first-order distinctions, such as a blue book (as opposed to no blue book), as well as many negative concepts, such as no bird (as opposed to a bird), no bicycle (as opposed to a bicycle), no bush (as opposed to a bush), and so on. Similarly, an experience of pure darkness and silence is the particular way it is\u2014it has the specific quality it has (no bedroom, no bed, no book, no blue, nor any other object, color, sound, thought, and so on). And being that way, it necessarily differs from a large number of alternative experiences I could have had but I am not actually having.\nIntegration: Consciousness is unified: each experience is irreducible and cannot be subdivided into non-interdependent, disjoint subsets of phenomenal distinctions. Thus, I experience a whole visual scene, not the left side of the visual field independent of the right side (and vice versa). For example, the experience of seeing the word \"BECAUSE\" written in the middle of a blank page is not reducible to an experience of seeing \"BE\" on the left plus an experience of seeing \"CAUSE\" on the right. Similarly, seeing a blue book is not reducible to seeing a book without the color blue, plus the color blue without the book.\nExclusion: Consciousness is definite, in content and spatio-temporal grain: each experience has the set of phenomenal distinctions it has, neither less (a subset) nor more (a superset), and it flows at the speed it flows, neither faster nor slower. For example, the experience I am having is of seeing a body on a bed in a bedroom, a bookcase with books, one of which is a blue book, but I am not having an experience with less content\u2014say, one lacking the phenomenal distinction blue/not blue, or colored/not colored; or with more content\u2014say, one endowed with the additional phenomenal distinction high/low blood pressure. Moreover, my experience flows at a particular speed\u2014each experience encompassing say a hundred milliseconds or so\u2014but I am not having an experience that encompasses just a few milliseconds or instead minutes or hours.\nPostulates: properties required of the physical substrate[edit]\nThe axioms describe regularities in conscious experience, and IIT seeks to explain these regularities. What could account for the fact that every experience exists, is structured, is differentiated, is unified, and is definite? IIT argues that the existence of an underlying causal system with these same properties offers the most parsimonious explanation. Thus a physical system, if conscious, is so by virtue of its causal properties.\nThe properties required of a conscious physical substrate are called the \"postulates,\" since the existence of the physical substrate is itself only postulated (remember, IIT maintains that the only thing one can be sure of is the existence of one's own consciousness). In what follows, a \"physical system\" is taken to be a set of elements, each with two or more internal states, inputs that influence that state, and outputs that are influenced by that state (neurons or logic gates are the natural examples). Given this definition of \"physical system\", the postulates are:\n\n\nIntrinsic existence: To account for the intrinsic existence of experience, a system constituted of elements in a state must exist intrinsically (be actual): specifically, in order to exist, it must have cause-effect power, as there is no point in assuming that something exists if nothing can make a difference to it, or if it cannot make a difference to anything. Moreover, to exist from its own intrinsic perspective, independent of external observers, a system of elements in a state must have cause-effect power upon itself, independent of extrinsic factors. Cause-effect power can be established by considering a cause-effect space with an axis for every possible state of the system in the past (causes) and future (effects). Within this space, it is enough to show that an \"intervention\" that sets the system in some initial state (cause), keeping the state of the elements outside the system fixed (background conditions), can lead with probability different from chance to its present state; conversely, setting the system to its present state leads with probability above chance to some other state (effect).\nComposition: The system must be structured: subsets of the elements constituting the system, composed in various combinations, also have cause-effect power within the system. Thus, if a system ABC is constituted of elements A, B, and C, any subset of elements (its power set), including A, B, C, AB, AC, BC, as well as the entire system, ABC, can compose a mechanism having cause-effect power. Composition allows for elementary (first-order) elements to form distinct higher-order mechanisms, and for multiple mechanisms to form a structure.\nInformation: The system must specify a cause-effect structure that is the particular way it is: a specific set of specific cause-effect repertoires\u2014thereby differing from other possible ones (differentiation). A cause-effect repertoire characterizes in full the cause-effect power of a mechanism within a system by making explicit all its cause-effect properties. It can be determined by perturbing the system in all possible ways to assess how a mechanism in its present state makes a difference to the probability of the past and future states of the system. Together, the cause-effect repertoires specified by each composition of elements within a system specify a cause-effect structure. ...\nIntegration: The cause-effect structure specified by the system must be unified: it must be intrinsically irreducible to that specified by non-interdependent sub-systems obtained by unidirectional partitions. Partitions are taken unidirectionally to ensure that cause-effect power is intrinsically irreducible\u2014from the system's intrinsic perspective\u2014which implies that every part of the system must be able to both affect and be affected by the rest of the system. Intrinsic irreducibility can be measured as integrated information (\"big phi\" or , a non-negative number), which quantifies to what extent the cause-effect structure specified by a system's elements changes if the system is partitioned (cut or reduced) along its minimum partition (the one that makes the least difference). By contrast, if a partition of the system makes no difference to its cause-effect structure, then the whole is reducible to those parts. If a whole has no cause-effect power above and beyond its parts, then there is no point in assuming that the whole exists in and of itself: thus, having irreducible cause-effect power is a further prerequisite for existence. This postulate also applies to individual mechanisms: a subset of elements can contribute a specific aspect of experience only if their combined cause-effect repertoire is irreducible by a minimum partition of the mechanism (\"small phi\" or ).\nExclusion: The cause-effect structure specified by the system must be definite: it is specified over a single set of elements\u2014neither less nor more\u2014the one over which it is maximally irreducible from its intrinsic perspective (), thus laying maximal claim to intrinsic existence. ... With respect to causation, this has the consequence that the \"winning\" cause-effect structure excludes alternative cause-effect structures specified over overlapping elements, otherwise there would be causal overdetermination. ... The exclusion postulate can be said to enforce Occam's razor (entities should not be multiplied beyond necessity): it is more parsimonious to postulate the existence of a single cause-effect structure over a system of elements\u2014the one that is maximally irreducible from the system's intrinsic perspective\u2014than a multitude of overlapping cause-effect structures whose existence would make no further difference. The exclusion postulate also applies to individual mechanisms: a subset of elements in a state specifies the cause-effect repertoire that is maximally irreducible (MICE) within the system (), called a core concept, or concept for short. Again, it cannot additionally specify a cause-effect repertoire overlapping over the same elements, because otherwise the difference a mechanism makes would be counted multiple times. ... Finally, the exclusion postulate also applies to spatio-temporal grains, implying that a conceptual structure is specified over a definite grain size in space (either quarks, atoms, neurons, neuronal groups, brain areas, and so on) and time (either microseconds, milliseconds, seconds, minutes, and so on), the one at which  reaches a maximum. ... Once more, this implies that a mechanism cannot specify a cause-effect repertoire at a particular temporal grain, and additional effects at a finer or coarser grain, otherwise the differences a mechanism makes would be counted multiple times.\nMathematics: formalization of the postulates[edit]\nFor a complete and thorough account of the mathematical formalization of IIT, see reference.[6] What follows is intended as a brief summary, adapted from,[10] of the most important quantities involved. Pseudocode for the algorithms used to calculate these quantities can be found at reference.[11] For a visual illustration of the algorithm, see the supplementary material of the paper describing the PyPhi toolbox.[12]\nA system refers to a set of elements, each with two or more internal states, inputs that influence that state, and outputs that are influenced by that state. A mechanism refers to a subset of system elements. The mechanism-level quantities below are used to assess the integration of any given mechanism, and the system-level quantities are used to assess the integration of sets of mechanisms (\"sets of sets\").\nIn order to apply the IIT formalism to a system, its full transition probability matrix (TPM) must be known. The TPM specifies the probability with which any state of a system transitions to any other system state. Each of the following quantities is calculated in a bottom-up manner from the system's TPM.\n\n\n\n\nMechanism-level quantities\n\n\nA cause-effect repertoire  is a set of two probability distributions, describing how the mechanism  in its current state  constrains the past and future states of the sets of system elements  and , respectively.\nNote that  may be different from , since the elements that a mechanism affects may be different from the elements that affect it.  \n\n\n\nA partition  is a grouping of system elements, where the connections between the parts  and  are injected with independent noise. For a simple binary element  which outputs to a simple binary element , injecting the connection  with independent noise means that the input value which  receives,  or , is entirely independent of the actual state of , thus rendering  causally ineffective.\n denotes a pair of partitions, one of which is considered when looking at a mechanism's causes, and the other of which is considered when looking at its effects.\n\n\n\nThe earth mover's distance  is used to measure distances between probability distributions  and . The EMD depends on the user's choice of ground distance between points in the metric space over which the probability distributions are measured, which in IIT is the system's state space. When computing the EMD with a system of simple binary elements, the ground distance between system states is chosen to be their Hamming distance.\n\n\nIntegrated information  measures the irreducibility of a cause-effect repertoire with respect to partition , obtained by combining the irreducibility of its constituent cause and effect repertoires with respect to the same partitioning.\nThe irreducibility of the cause repertoire with respect to  is given by , and similarly for the effect repertoire.\nCombined,  and  yield the irreducibility of the  as a whole: . \n\n\n\nThe minimum-information partition of a mechanism and its purview is given by . The minimum-information partition is the partitioning that least affects a cause-effect repertoire. For this reason, it is sometimes called the minimum-difference partition.\nNote that the minimum-information \"partition\", despite its name, is really a pair of partitions. We call these partitions  and .\n\n\n\nThere is at least one choice of elements over which a mechanism's cause-effect repertoire is maximally irreducible (in other words, over which its  is highest). We call this choice of elements , and say that this choice specifies a maximally irreducible cause-effect repertoire.\nFormally,  and .\n\n\n\nThe concept  is the maximally irreducible cause-effect repertoire of mechanism in its current state  over , and describes the causal role of  within the system. Informally,  is the concept's purview, and specifies what the concept \"is about\".\nThe intrinsic cause-effect power of  is the concept's strength, and is given by:\n\n\n\n\n\n\n\nSystem-level quantities\n\n\nA cause-effect structure  is the set of concepts specified by all mechanisms with  within the system  in its current state . If a system turns out to be conscious, its cause-effect structure is often referred to as a conceptual structure.\n\n\nA unidirectional partition  is a grouping of system elements where the connections from the set of elements  to  are injected with independent noise.\n\n\nThe extended earth mover's distance  is used to measure the minimal cost of transforming cause-effect structure  into structure . Informally, one can say that\u2013whereas the EMD transports the probability of a system state over the distance between two system states\u2013the XEMD transports the strength of a concept over the distance between two concepts.\nIn the XEMD, the \"earth\" to be transported is intrinsic cause-effect power (), and the ground distance between concepts  and  with cause repertoires  and  and effect repertoires  and  is given by . \n\n\n\nIntegrated (conceptual) information  measures the irreducibility of a cause-effect structure with respect to a unidirectional partition.  captures how much the cause-effect repertoires of the system's mechanisms are altered and how much intrinsic cause effect power () is lost due to partition .\n\n\nThe minimum-information partition of a set of elements in a state is given by . The minimum-information partition is the unidirectional partition that least affects a cause-effect structure .\n\n\nThe intrinsic cause-effect power of a set of elements in a state is given by , such that for any other  with , . According to IIT, a system's  is the degree to which it can be said to exist.\n\n\nA complex is a set of elements  with , and thus specifies a maximally irreducible cause-effect structure, also called a conceptual structure. According to IIT, complexes are conscious entities.\n\n\nCause-effect space[edit]\nFor a system of  simple binary elements, cause-effect space is formed by  axes, one for each possible past and future state of the system. Any cause-effect repertoire , which specifies the probability of each possible past and future state of the system, can be easily plotted as a point in this high-dimensional space: The position of this point along each axis is given by the probability of that state as specified by . If a point is also taken to have a scalar magnitude (which can be informally thought of as the point's \"size\", for example), then it can easily represent a concept: The concept's cause-effect repertoire specifies the location of the point in cause-effect space, and the concept's  value specifies that point's magnitude.\nIn this way, a conceptual structure  can be plotted as a constellation of points in cause-effect space. Each point is called a star, and each star's magnitude () is its size.\n\nCentral identity[edit]\nIIT addresses the mind-body problem by proposing an identity between phenomenological properties of experience and causal properties of physical systems: The conceptual structure specified by a complex of elements in a state is identical to its experience.\nSpecifically, the form of the conceptual structure in cause-effect space completely specifies the quality of the experience, while the irreducibility  of the conceptual structure specifies the level to which it exists (i.e., the complex's level of consciousness).  The maximally irreducible cause-effect repertoire of each concept within a conceptual structure specifies what the concept contributes to the quality of the experience, while its irreducibility  specifies how much the concept is present in the experience.\nAccording to IIT, an experience is thus an intrinsic property of a complex of mechanisms in a state.\n\nExtensions[edit]\nThe calculation of even a modestly-sized system's  is often computationally intractable,[12] so efforts have been made to develop heuristic or proxy measures of integrated information. For example, Masafumi Oizumi and colleagues have developed both [13] and geometric integrated information or ,[14] which are practical approximations for integrated information. These are related to proxy measures developed earlier by Anil Seth and Adam Barrett.[15] However, none of these proxy measures have a mathematically proven relationship to the actual  value, which complicates the interpretation of analyses that use them. They can give qualitatively different results even for very small systems.[16]\nA significant computational challenge in calculating integrated information is finding the Minimum Information Partition of a neural system, which requires iterating through all possible network partitions. To solve this problem, Daniel Toker and Friedrich T. Sommer have shown that the spectral decomposition of the correlation matrix of a system's dynamics is a quick and robust proxy for the Minimum Information Partition.[17]\n\n[edit]\nWhile the algorithm[12][11] for assessing a system's  and conceptual structure is relatively straightforward, its high time complexity makes it computationally intractable for many systems of interest.[12] Heuristics and approximations can sometimes be used to provide ballpark estimates of a complex system's integrated information, but precise calculations are often impossible. These computational challenges, combined with the already difficult task of reliably and accurately assessing consciousness under experimental conditions, make testing many of the theory's predictions difficult.\nDespite these challenges, researchers have attempted to use measures of information integration and differentiation to assess levels of consciousness in a variety of subjects.[18][19] For instance, a recent study using a less computationally-intensive proxy for  was able to reliably discriminate between varying levels of consciousness in wakeful, sleeping (dreaming vs. non-dreaming), anesthetized, and comatose (vegetative vs. minimally-conscious vs. locked-in) individuals.[20]\nIIT also makes several predictions which fit well with existing experimental evidence, and can be used to explain some counterintuitive findings in consciousness research.[1] For example, IIT can be used to explain why some brain regions, such as the cerebellum do not appear to contribute to consciousness, despite their size and/or functional importance.\n\nReception[edit]\nThis section needs expansion. You can help by adding to it.  (May 2016)\nIntegrated Information Theory has received both broad criticism and support.\n\nSupport[edit]\nNeuroscientist Christof Koch, who has helped to develop the theory, has called IIT \"the only really promising fundamental theory of consciousness\".[21]  Technologist and ex-IIT researcher Virgil Griffith says \"IIT is currently the leading theory of consciousness.\"  However, his answer to whether IIT is a valid theory is \u2018Probably not\u2019.[22]\nDaniel Dennett considers IIT a theory of consciousness in terms of \u201cintegrated information that uses Shannon information theory in a novel way\u201d. As such it has \u201ca very limited role for aboutness: it measures the amount of Shannon information a system or mechanism has about its own previous state\u2014i.e., the states of all its parts\u201d.[23]\n\nCriticism[edit]\nOne criticism made is that the claims of IIT as a theory of consciousness \u201care not scientifically established or testable at the moment\u201d.[24] However, while it is true that the complete analysis suggested by IIT cannot be completed at the moment for human brains, IIT has already been applied to models of visual cortex to rigorously and successfully to explain why visual space feels the way it does.[2]\nNeuroscientists Bj\u00f6rn Merker, David Rudrauf and Philosopher Kenneth Williford co-authored a paper criticizing IIT on several grounds. Firstly, by not demonstrating that all members of systems which do in fact combine integration and differentiation in the formal IIT sense are conscious, systems which demonstrate high levels of integration and differentiation of information might provide the necessary conditions for consciousness but those combinations of attributes do not amount to the conditions for consciousness. Secondly that the measure, \u03a6, reflects efficiency of global information transfer rather than level of consciousness, and that the correlation of \u03a6 with level of consciousness through different states of wakefulness (e.g. awake, dreaming and dreamless sleep, anesthesia, seizures and coma) actually reflect the level of efficient network interactions performed for cortical engagement. Hence \u03a6 reflects network efficiency rather than consciousness, which would be one of the functions served by cortical network efficiency.[25] Of course, IIT emphasizes the importance of all five postulates being satisfied (not just information and integration) and does not claim that \u03a6 is identical to consciousness, undermining the authors credibility on the topic of IIT and leaving their main criticism hamstrung.[26] \nPrinceton neuroscientist Michael Graziano rejects IIT as pseudoscience. He claims IIT is a \"magicalist theory\" that has \"no chance of scientific success or understanding\".[27] \nTheoretical computer scientist Scott Aaronson has criticized IIT by demonstrating through its own formulation that an inactive series of logic gates, arranged in the correct way, would not only be conscious but be \u201cunboundedly more conscious than humans are.\u201d[28] Tononi himself agrees with the assessment and argues that according to IIT, an even simpler arrangement of inactive logic gates, if large enough, would also be conscious. However he further argues that this is a strength of IIT rather than a weakness.[29][30]\nA peer-reviewed commentary by 58 scholars involved in the scientific study of consciousness rejects these conclusions about logic gates as \u201cmysterious and unfalsifiable claims\u201d that should be distinguished from \u201cempirically productive hypotheses\u201d.[31][clarification needed] IIT as a scientific theory of consciousness has been criticized in the scientific literature as only able to be \u201ceither false or unscientific\u201d by its own definitions.[32] IIT has also been denounced by other members of the consciousness field as requiring \u201can unscientific leap of faith\u201d, but it is not clear that this is in fact the case if the theory is properly understood.[33]  The theory has also been derided for failing to answer the basic questions required of a theory of consciousness.  Philosopher Adam Pautz says \u201cAs long as proponents of IIT do not address these questions, they have not put a clear theory on the table that can be evaluated as true or false.\u201d[34]\nInfluential philosopher John Searle has given a critique of theory saying \"The theory implies panpsychism\" and \"The problem with panpsychism is not that it is false; it does not get up to the level of being false. It is strictly speaking meaningless because no clear notion has been given to the claim.\".[35] However, whether or not a theory has panpsychist implications (that all or most of what exists physically must be, be part of something that is, or be composed of parts that are, conscious) has no bearing on the scientific validity of the theory.\nThe mathematics of IIT have also been criticized since \u201chaving a high \u03a6 value requires highly specific structures that are unstable to minor perturbations\u201d.[36]  This susceptibility to minor perturbations seems inconsistent with empirical results about neuroplasticity in the human brain, and thus weakening the theory. However, the systems investigated by Schwitzgebel were small networks of logic gates, and not human brains in normal waking conditions, and the generalizability to systems about which we have access to verified conscious experience (human beings) is questionable.\nThe computational tractability of the \u03a6 measure has been put into question. According to Max Tegmark \u201cthe integration measure proposed by IIT is computationally infeasible to evaluate for large systems, growing super-exponentially with the system\u2019s information content.\u201d[37] As a result, \u03a6 can only be approximated in general. However, different ways of approximating \u03a6 provide radically different results.[38] Other works have shown that \u03a6 can be computed in some large mean-field neural network models, although some assumptions of the theory have to be revised to capture phase transitions in these large systems.[39][40]\nPhilosopher Tim Bayne has criticized the axiomatic foundations of the theory.[41] He concludes that \u201cthe so-called \u2018axioms\u2019 that Tononi et al. appeal to fail to qualify as genuine axioms\u201d.\nVarious aspects of IIT have also been subject to criticism. These include:\n\nIIT proposes conditions which are necessary for consciousness, but critics suggest that they may not be entirely sufficient.[42]\nIIT is said to claim that its axioms are self-evident.[43][clarification needed]\nFunctionalist philosophers have criticised IIT for being non-functionalist.[43]\nThe definition of consciousness in IIT has been directly criticised.[42][43][clarification needed]\nSee also[edit]\n\n\nCausality\nConsciousness\nHard problem of consciousness\nMind\u2013body problem\nNeural correlates of consciousness\nPhenomenology (philosophy)\nPhenomenology (psychology)\nPhilosophy of mind\nQualia\nSentience\n\nReferences[edit]\n\n^ Jump up to: a b c d e Tononi, Giulio (2015). \"Integrated information theory\". Scholarpedia. 10 (1): 4164. Bibcode:2015SchpJ..10.4164T. doi:10.4249/scholarpedia.4164.\n\n^ Jump up to: a b c Haun, Andrew; Tononi, Giulio (December 2019). \"Why Does Space Feel the Way it Does? Towards a Principled Account of Spatial Experience\". Entropy. 21 (12): 1160. Bibcode:2019Entrp..21.1160H. doi:10.3390/e21121160. PMC\u00a07514505.\n\n^ Tononi, Giulio; Koch, Christof (2015-05-19). \"Consciousness: here, there and everywhere?\". Philosophical Transactions of the Royal Society B: Biological Sciences. 370 (1668): 20140167. doi:10.1098/rstb.2014.0167. ISSN\u00a00962-8436. PMC\u00a04387509. PMID\u00a025823865.\n\n^ Tononi, Giulio; Boly, Melanie; Massimini, Marcello; Koch, Christof (2016). \"Integrated information theory: from consciousness to its physical substrate\". Nature Reviews Neuroscience. 17 (7): 450\u2013461. doi:10.1038/nrn.2016.44. PMID\u00a027225071. S2CID\u00a021347087.\n\n^ Tononi, Giulio (2004-11-02). \"An information integration theory of consciousness\". BMC Neuroscience. 5 (1): 42. doi:10.1186/1471-2202-5-42. ISSN\u00a01471-2202. PMC\u00a0543470. PMID\u00a015522121.\n\n^ Jump up to: a b Oizumi, Masafumi; Albantakis, Larissa; Tononi, Giulio (2014-05-08). \"From the Phenomenology to the Mechanisms of Consciousness: Integrated Information Theory 3.0\". PLOS Comput Biol. 10 (5): e1003588. Bibcode:2014PLSCB..10E3588O. doi:10.1371/journal.pcbi.1003588. PMC\u00a04014402. PMID\u00a024811198.\n\n^ Barbosa, Leonardo S.; Marshall, William; Streipert, Sabrina; Albantakis, Larissa; Tononi, Giulio (2020-11-02). \"A measure for intrinsic information\". Scientific Reports. 10 (1): 18803. Bibcode:2020NatSR..1018803B. doi:10.1038/s41598-020-75943-4. ISSN\u00a02045-2322. PMC\u00a07606539. PMID\u00a033139829.\n\n^ Barbosa, Leonardo S.; Marshall, William; Albantakis, Larissa; Tononi, Giulio (March 2021). \"Mechanism Integrated Information\". Entropy. 23 (3): 362. Bibcode:2021Entrp..23..362B. doi:10.3390/e23030362. PMC\u00a08003304. PMID\u00a033803765.\n\n^ Marshall, William; Albantakis, Larissa; Tononi, Giulio (2018-04-23).  Schrater, Paul (ed.). \"Black-boxing and cause-effect power\". PLOS Computational Biology. 14 (4): e1006114. arXiv:1608.03461. Bibcode:2018PLSCB..14E6114M. doi:10.1371/journal.pcbi.1006114. ISSN\u00a01553-7358. PMC\u00a05933815. PMID\u00a029684020.\n\n^ Albantakis, Larissa; Tononi, Giulio (2015-07-31). \"The Intrinsic Cause-Effect Power of Discrete Dynamical Systems\u2014From Elementary Cellular Automata to Adapting Animats\". Entropy. 17 (8): 5472\u20135502. Bibcode:2015Entrp..17.5472A. doi:10.3390/e17085472.\n\n^ Jump up to: a b \"CSC-UW/iit-pseudocode\". GitHub. Retrieved 2016-01-29.\n\n^ Jump up to: a b c d Mayner, William G. P.; Marshall, William; Albantakis, Larissa; Findlay, Graham; Marchman, Robert; Tononi, Giulio (2018-07-26). \"PyPhi: A toolbox for integrated information theory\". PLOS Computational Biology. 14 (7): e1006343. arXiv:1712.09644. Bibcode:2018PLSCB..14E6343M. doi:10.1371/journal.pcbi.1006343. ISSN\u00a01553-7358. PMC\u00a06080800. PMID\u00a030048445.\n\n^ Oizumi, Masafumi; Amari, Shun-ichi; Yanagawa, Toru; Fujii, Naotaka; Tsuchiya, Naotsugu (2015-05-17). \"Measuring integrated information from the decoding perspective\". PLOS Computational Biology. 12 (1): e1004654. arXiv:1505.04368. Bibcode:2016PLSCB..12E4654O. doi:10.1371/journal.pcbi.1004654. PMC\u00a04721632. PMID\u00a026796119.\n\n^ Oizumi, Masafumi; Tsuchiya, Naotsugu; Amari, Shun-ichi (20 December 2016). \"Unified framework for information integration based on information geometry\". Proceedings of the National Academy of Sciences. 113 (51): 14817\u201314822. doi:10.1073/pnas.1603583113. PMC\u00a05187746. PMID\u00a027930289.\n\n^ Barrett, A.B.; Seth, A.K. (2011). \"Practical measures of integrated information for time-series data\". PLOS Comput. Biol. 7 (1): e1001052. Bibcode:2011PLSCB...7E1052B. doi:10.1371/journal.pcbi.1001052. PMC\u00a03024259. PMID\u00a021283779.\n\n^ Mediano, Pedro; Seth, Anil; Barrett, Adam (2018-12-25). \"Measuring Integrated Information: Comparison of Candidate Measures in Theory and Simulation\". Entropy. 21 (1): 17. arXiv:1806.09373. Bibcode:2018Entrp..21...17M. doi:10.3390/e21010017. ISSN\u00a01099-4300. PMC\u00a07514120. PMID\u00a033266733.\n\n^ Toker, Daniel; Sommer, Friedrich T.; Marinazzo, Daniele (7 February 2019). \"Information integration in large brain networks\". PLOS Computational Biology. 15 (2): e1006807. Bibcode:2019PLSCB..15E6807T. doi:10.1371/journal.pcbi.1006807. PMC\u00a06382174. PMID\u00a030730907.\n\n^ Massimini, M.; Ferrarelli, F.; Murphy, Mj; Huber, R.; Riedner, Ba; Casarotto, S.; Tononi, G. (2010-09-01). \"Cortical reactivity and effective connectivity during REM sleep in humans\". Cognitive Neuroscience. 1 (3): 176\u2013183. doi:10.1080/17588921003731578. ISSN\u00a01758-8936. PMC\u00a02930263. PMID\u00a020823938.\n\n^ Ferrarelli, Fabio; Massimini, Marcello; Sarasso, Simone; Casali, Adenauer; Riedner, Brady A.; Angelini, Giuditta; Tononi, Giulio; Pearce, Robert A. (2010-02-09). \"Breakdown in cortical effective connectivity during midazolam-induced loss of consciousness\". Proceedings of the National Academy of Sciences of the United States of America. 107 (6): 2681\u20132686. Bibcode:2010PNAS..107.2681F. doi:10.1073/pnas.0913008107. ISSN\u00a01091-6490. PMC\u00a02823915. PMID\u00a020133802.\n\n^ Casali, Adenauer G.; Gosseries, Olivia; Rosanova, Mario; Boly, M\u00e9lanie; Sarasso, Simone; Casali, Karina R.; Casarotto, Silvia; Bruno, Marie-Aur\u00e9lie; Laureys, Steven; Massimini, Marcello (2013-08-14). \"A Theoretically Based Index of Consciousness Independent of Sensory Processing and Behavior\". Science Translational Medicine. 5 (198): 198ra105. doi:10.1126/scitranslmed.3006294. hdl:2268/171542. ISSN\u00a01946-6234. PMID\u00a023946194. S2CID\u00a08686961.\n\n^ Zimmer, Carl (2010-09-20). \"Sizing Up Consciousness by Its Bits\". The New York Times. ISSN\u00a00362-4331. Retrieved 2015-11-23.\n\n^ \"How valid is Giulio Tononi's mathematical formula for consciousness?\".\n\n^ Dennett D., From Bacteria to Bach and Back., Norton and Co, New York, 2017, page 127.\n\n^ au, Hakwan (28 May 2020). \"Open letter to NIH on Neuroethics Roadmap (BRAIN initiative) 2019\". In Consciousness We Trust..\n\n^ Merker, Bj\u00f6rn (19 May 2021). \"The Integrated Information Theory of consciousness: A case of mistaken identity\". BBS Behavioral and Brain Sciences: 1\u201372. doi:10.1017/S0140525X21000881. PMID\u00a034006338. Retrieved 1 Jun 2021.\n\n^ Oizumi, Masafumi; Albantakis, Larissa; Tononi, Giulio (2014-05-08). \"From the Phenomenology to the Mechanisms of Consciousness: Integrated Information Theory 3.0\". PLOS Computational Biology. 10 (5): e1003588. Bibcode:2014PLSCB..10E3588O. doi:10.1371/journal.pcbi.1003588. ISSN\u00a01553-7358. PMC\u00a04014402. PMID\u00a024811198.\n\n^ Jarrett, Christian (5 April 2020). \"Consciousness: how can we solve the greatest mystery in science?\". BBC Science Focus Magazine. Retrieved 2 February 2021.\n\n^ Aaronson, Scott. \"Why I Am Not An Integrated Information Theorist (or, The Unconscious Expander)\". Shetl-Optimized: The Blog of Scott Aaronson.\n\n^ Aaronson, Scott. \"Giulio Tononi and Me: A Phi-nal Exchange\". Shetl-Optimized: The Blog of Scott Aaronson.\n\n^ Tononi, Giulio. \"Why Scott should stare at a blank wall and reconsider (or, the conscious grid)\". Shetl-Optimized: The Blog of Scott Aaronson.\n\n^ Michel, Matthias; Beck, Diane; Block, Ned; Blumenfeld, Hal; Brown, Richard; Carmel, David; Carrasco, Marisa; Chirimuuta, Mazviita; Chun, Marvin; Cleeremans, Axel; Dehaene, Stanislas; Fleming, Stephen; Frith, Chris; Haggard, Patrick; He, Biyu; Heyes, Cecilia; Goodale, Mel; Irvine, Liz; Kawato, Mitsuo; Kentridge, Robert; King, JR; Knight, Robert; Kouider, Sid; Lamme, Victor; Lamy, Dominique; Lau, Hakwan; Laureys, Steven; LeDoux, Joseph; Lin, Ying-Tung; Liu, Kayuet; Macknik, Stephen; Martinez-Conde, Susana; Mashour, George; Melloni, Lucia; Miracchi, Lisa; Mylopoulos, Myrto; Naccache, Lionel; Owen, Adrian; Passingham, Richard; Pessoa, Luiz; Peters, Megan; Rahnev, Dobromir; Ro, Tony; Rosenthal, David; Sasaki, Yuka; Sergent, Claire; Solovey, Guillermo; Schiff, Nicholas; Seth, Anil; Tallon-Baudry, Catherine; Tamietto, Marco; Tong, Frank; van Gaal, Simon; Vlassova, Alexandra; Watanabe, Takeo; Weisberg, Josh; Yan, Karen; Yoshida, Masatoshi (February 4, 2019). \"Opportunities and challenges for a maturing science of consciousness\". Nature Human Behaviour. 3 (2): 104\u2013107. doi:10.1038/s41562-019-0531-8. PMC\u00a06568255. PMID\u00a030944453.\n\n^ Doerig, Adrian; Schruger, Aaron; Hess, Kathryn; Herzog, Michael (2019). \"The unfolding argument: Why IIT and other causal structure theories cannot explain consciousness\". Consciousness and Cognition. 72: 49\u201359. doi:10.1016/j.concog.2019.04.002. PMID\u00a031078047.\n\n^ Lau, Hakwan; Michel, Matthias (2019). \"On the dangers of conflating strong and weak versions of a theory of consciousness\". PsyArXiv. doi:10.31234/osf.io/hjp3s.\n\n^ Pautz, Adam (2019). \"What is Integrated Information Theory?: A Catalogue of Questions\". Journal of Consciousness Studies. 26` (1): 188\u2013215.\n\n^ Searle, John. \"Can Information Theory Explain Consciousness?\". The New York Review of Books.\n\n^ Schwitzgebel, Eric (9 November 2018). \"The Phi Value of Integrated Information Theory Might Not Be Stable Across Small Changes in Neural Connectivity\". The Splintered Mind: Reflections in Philosophy of Psychology, Broadly Contrued.\n\n^ Tegmark, Max (2016). \"Improved Measures of Integrated Information\". PLOS Computational Biology. 12 (11): e1005123. arXiv:1601.02626. Bibcode:2016PLSCB..12E5123T. doi:10.1371/journal.pcbi.1005123. PMC\u00a05117999. PMID\u00a027870846.\n\n^ Mediano, Pedro; Seth, Anil; Barrett, Adam (2019). \"Measuring Integrated Information: Comparison of Candidate Measures in Theory and Simulation\". Entropy. 21 (1): 17. doi:10.3390/e21010017. PMC\u00a07514120. PMID\u00a033266733.\n\n^ Aguilera, Miguel; Di Paolo, Ezequiel (2019). \"Integrated information in the thermodynamic limit\". Neural Networks. 114: 136\u2013146. doi:10.1016/j.neunet.2019.03.001. PMID\u00a030903946.\n\n^ Aguilera, Miguel (2019). \"Scaling Behaviour and Critical Phase Transitions in Integrated Information Theory\". Entropy. 21 (12): 1198. Bibcode:2019Entrp..21.1198A. doi:10.3390/e21121198.\n\n^ Bayne, Tim (2018). \"On the axiomatic foundations of the integrated information theory of consciousness\". Neuroscience of Consciousness. 2018 (1): niy007. doi:10.1093/nc/niy007. PMC\u00a06030813. PMID\u00a030042860.\n\n^ Jump up to: a b \"Shtetl-Optimized\u00a0\u00bb Blog Archive\u00a0\u00bb Why I Am Not An Integrated Information Theorist (or, The Unconscious Expander)\". www.ScottAaronson.com. Retrieved 23 November 2015.\n\n^ Jump up to: a b c Cerullo, Michael A. (17 September 2015). \"The Problem with Phi: A Critique of Integrated Information Theory\". PLOS Computational Biology. 11 (9): e1004286. Bibcode:2015PLSCB..11E4286C. doi:10.1371/journal.pcbi.1004286. PMC\u00a04574706. PMID\u00a026378789.\n\n\nExternal links[edit]\n\n[edit]\nTononi, Giulio; Boly, Melanie; Massimini, Marcello; Koch, Christof (2016). \"Integrated information theory: From consciousness to its physical substrate\". Nature Reviews Neuroscience. 17 (7): 450\u2013461. doi:10.1038/nrn.2016.44. PMID\u00a027225071. S2CID\u00a021347087.\nTononi, Giulio (2015). \"Integrated information theory\". Scholarpedia. 10 (1): 4164. Bibcode:2015SchpJ..10.4164T. doi:10.4249/scholarpedia.4164.\nOizumi, Masafumi; Albantakis, Larissa; Tononi, Giulio (2014). \"From the Phenomenology to the Mechanisms of Consciousness: Integrated Information Theory 3.0\". PLOS Computational Biology. 10 (5): e1003588. Bibcode:2014PLSCB..10E3588O. doi:10.1371/journal.pcbi.1003588. PMC\u00a04014402. PMID\u00a024811198. S2CID\u00a02578087.\nIntegrated Information Theory: An Updated Account (2012) (First presentation of IIT 3.0)\nTononi, Giulio (2008). \"Consciousness as Integrated Information: A Provisional Manifesto\". The Biological Bulletin. 215 (3): 216\u2013242. doi:10.2307/25470707. JSTOR\u00a025470707. PMID\u00a019098144.\nTononi, Giulio (2004). \"An information integration theory of consciousness\". BMC Neuroscience. 5: 42. doi:10.1186/1471-2202-5-42. PMC\u00a0543470. PMID\u00a015522121.\nWebsites[edit]\nintegratedinformationtheory.org: resource for learning about IIT; features a graphical user interface to PyPhi.\n\"Integrated Information Theory of Consciousness\". Internet Encyclopedia of Philosophy.\nSoftware[edit]\nPyPhi: an open-source Python package for calculating integrated information.\nMayner, William G. P.; Marshall, William; Albantakis, Larissa; Findlay, Graham; Marchman, Robert; Tononi, Giulio (2018). \"PyPhi: A toolbox for integrated information theory\". PLOS Computational Biology. 14 (7): e1006343. arXiv:1712.09644. Bibcode:2018PLSCB..14E6343M. doi:10.1371/journal.pcbi.1006343. PMC\u00a06080800. PMID\u00a030048445.\nGraphical user interface\nDocumentation\nBooks[edit]\nThe Feeling of Life Itself: Why Consciousness is Widespread but Can't Be Computed by Christof Koch (2019)\nPhi: A Voyage from the Brain to the Soul by Giulio Tononi (2012)\nNews articles[edit]\nNew Scientist (2019): How does consciousness work? A radical theory has mind-blowing answers\nNautilus (2017): Is Matter Conscious?\nAeon (2016): Consciousness creep\nMIT Technology Review (2014): What It Will Take for Computers to Be Conscious\nWired (2013): A Neuroscientist's Radical Theory of How Networks Become Conscious\nThe New Yorker (2013): How Much Consciousness Does an iPhone Have?\nNew York Times (2010): Sizing Up Consciousness by Its Bits\nScientific American (2009): A \"Complex\" Theory of Consciousness\nIEEE Spectrum (2008): A Bit of Theory: Consciousness as Integrated Information Theory\nTalks[edit]\nDavid Chalmers (2014): How do you explain consciousness?\nChristof Koch (2014): The Integrated Information Theory of Consciousness\n\n\n\n\n\n"
                ],
                "output": "readability",
                "pwd": "/home/wesleyac/code/notebook/data/archivebox/archive/1632689273.123244",
                "schema": "ArchiveResult",
                "start_ts": "2021-09-26T20:48:05.488338+00:00",
                "status": "succeeded"
            }
        ],
        "screenshot": [
            {
                "cmd": [
                    "chromium-browser",
                    "--headless",
                    "--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.61 Safari/537.36 ArchiveBox/{VERSION} (+https://github.com/ArchiveBox/ArchiveBox/)",
                    "--window-size=1440,2000",
                    "--timeout=90000",
                    "--screenshot",
                    "https://en.wikipedia.org/wiki/Integrated_information_theory"
                ],
                "cmd_version": "Chromium 93.0.4577.82",
                "end_ts": "2021-09-26T20:48:04.172511+00:00",
                "index_texts": null,
                "output": "screenshot.png",
                "pwd": "/home/wesleyac/code/notebook/data/archivebox/archive/1632689273.123244",
                "schema": "ArchiveResult",
                "start_ts": "2021-09-26T20:48:02.385939+00:00",
                "status": "succeeded"
            }
        ],
        "singlefile": [
            {
                "cmd": [
                    "/home/wesleyac/code/notebook/data/archivebox/node_modules/single-file/cli/single-file",
                    "--browser-executable-path=chromium-browser",
                    "--browser-args=[\"--headless\", \"--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.61 Safari/537.36 ArchiveBox/{VERSION} (+https://github.com/ArchiveBox/ArchiveBox/)\", \"--window-size=1440,2000\"]",
                    "https://en.wikipedia.org/wiki/Integrated_information_theory",
                    "singlefile.html"
                ],
                "cmd_version": "0.3.31",
                "end_ts": "2021-09-26T20:48:02.371724+00:00",
                "index_texts": null,
                "output": "singlefile.html",
                "pwd": "/home/wesleyac/code/notebook/data/archivebox/archive/1632689273.123244",
                "schema": "ArchiveResult",
                "start_ts": "2021-09-26T20:47:54.051213+00:00",
                "status": "succeeded"
            }
        ],
        "title": [
            {
                "cmd": [
                    "curl",
                    "--silent",
                    "--location",
                    "--compressed",
                    "--max-time",
                    "90",
                    "--user-agent",
                    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.61 Safari/537.36 ArchiveBox/0.6.2 (+https://github.com/ArchiveBox/ArchiveBox/) curl/curl 7.76.1 (x86_64-pc-linux-gnu)",
                    "https://en.wikipedia.org/wiki/Integrated_information_theory"
                ],
                "cmd_version": "curl 7.76.1 (x86_64-pc-linux-gnu)",
                "end_ts": "2021-09-26T20:47:53.667150+00:00",
                "index_texts": null,
                "output": "Integrated information theory - Wikipedia",
                "pwd": "/home/wesleyac/code/notebook/data/archivebox/archive/1632689273.123244",
                "schema": "ArchiveResult",
                "start_ts": "2021-09-26T20:47:53.252003+00:00",
                "status": "succeeded"
            }
        ],
        "wget": []
    },
    "icons": null,
    "is_archived": true,
    "is_static": false,
    "latest": {
        "archive_org": "https://web.archive.org/web/20210926204820/https://en.wikipedia.org/wiki/Integrated_information_theory",
        "dom": "output.html",
        "favicon": "favicon.ico",
        "git": null,
        "media": null,
        "pdf": null,
        "screenshot": "screenshot.png",
        "singlefile": "singlefile.html",
        "title": "Integrated information theory - Wikipedia",
        "warc": null,
        "wget": null
    },
    "link_dir": "/home/wesleyac/code/notebook/data/archivebox/archive/1632689273.123244",
    "newest_archive_date": "2021-09-26T20:48:18.064777+00:00",
    "num_failures": 0,
    "num_outputs": 9,
    "oldest_archive_date": "2021-09-26T20:47:53.252003+00:00",
    "path": "/wiki/Integrated_information_theory",
    "schema": "Link",
    "scheme": "https",
    "snapshot_id": "8f0c0693-5ac1-47bc-adbd-a45793752f37",
    "sources": [
        "/home/wesleyac/code/notebook/data/archivebox/sources/1632689273-import.txt"
    ],
    "tags": null,
    "tags_str": "",
    "timestamp": "1632689273.123244",
    "title": "Integrated information theory - Wikipedia",
    "updated": "2021-09-26T20:47:53.250620+00:00",
    "updated_date": "2021-09-26 20:47",
    "url": "https://en.wikipedia.org/wiki/Integrated_information_theory"
}